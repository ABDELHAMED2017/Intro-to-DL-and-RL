{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework  Exercise  3\n",
    "\n",
    "Full Name: Vasileios Lioutas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this exercise, I had to develop two text classification models using Vanilla RNN and LSTM for the IMDB Movie Review Dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 0 - Install necessary libraries (Skip if already installed)\n",
    "\n",
    "The following libraries are needed to be installed along with PyTorch in order to run the following notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "pip install torchtext\n",
    "pip install spacy\n",
    "python -m spacy download en"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1 - Load the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "from torchtext import data\n",
    "from torchtext import datasets\n",
    "from torchtext.vocab import GloVe\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "torch.backends.cudnn.enabled=True # make sure we use CuDNN for faster code\n",
    "\n",
    "SEED = 123\n",
    "\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "\n",
    "use_cuda = True\n",
    "device = torch.device(\"cuda\") if use_cuda else torch.device(\"cpu\")\n",
    "\n",
    "use_glove = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2 - Load dataset\n",
    "\n",
    "In order to load the dataset, I used the library \"torchtext\". Torchtext provides pre-built loaders for common NLP datasets (i.e. IMDB dataset) and gives you the flexibility to build a vocabulary of the word easily and with support of pre-trained vectors like Glove.\n",
    "\n",
    "For my experiments, I chose to use also Spacy (one of the best advanced NLP libraries for Python) to perform the tokenization of the words. I've decided to work with the version of Glove that is contains 6 billion tokens and the 300D vectors. More information can be found here: https://nlp.stanford.edu/projects/glove/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getData(batch_size=128, use_glove=False, device=torch.device(\"cpu\")):\n",
    "\n",
    "    # set up fields\n",
    "    TEXT = data.Field(lower=True, include_lengths=True, batch_first=True, tokenize='spacy')\n",
    "    LABEL = data.Field(sequential=False, dtype=torch.float32, unk_token=None, is_target=True)\n",
    "\n",
    "    # make splits for data\n",
    "    train, test = datasets.IMDB.splits(TEXT, LABEL)\n",
    "    \n",
    "    # build the vocabulary\n",
    "    if use_glove:\n",
    "        TEXT.build_vocab(train, max_size=25000, vectors=GloVe(name='6B', dim=300))\n",
    "    else:\n",
    "        TEXT.build_vocab(train)\n",
    "        \n",
    "    LABEL.build_vocab(train)\n",
    "\n",
    "    # make iterator for splits\n",
    "    train_iter, test_iter = data.BucketIterator.splits(\n",
    "        (train, test), sort_key=lambda x: len(x.text), \n",
    "        batch_sizes=(batch_size, 300), sort_within_batch=True, device=device, repeat=False)\n",
    "\n",
    "    return train_iter, test_iter, TEXT.vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we use the defined function to load the dataset. This will take some time the first time to download the dataset and the Glove vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_iterator,testing_iterator,vocabulary = getData(batch_size=16, device=device, use_glove=use_glove)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3 - Defining the model\n",
    "\n",
    "Below I've created a function to help me build all the different RNN models that I'll use for my experiments. It supports stacked RNNs, bidirectional RNNs and dropout."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, model='vanilla', vocab=None, hidden_size=128, dropout=0.5, num_layers=1, bidirectional=False):\n",
    "        super(RNN, self).__init__()\n",
    "        self.model = model\n",
    "        self.vocab = vocab\n",
    "        self.hidden_size = hidden_size\n",
    "        self.dropout = dropout\n",
    "        self.num_layers = num_layers\n",
    "        self.bidirectional = bidirectional\n",
    "        \n",
    "        self.emb_size = 300\n",
    "        \n",
    "        if self.vocab.vectors is None:\n",
    "            self.emb = nn.Embedding(len(self.vocab), self.emb_size)\n",
    "        else:\n",
    "            self.emb = nn.Embedding(len(self.vocab), self.vocab.vectors.shape[1], padding_idx=1) # we define which id corresponds to pad id\n",
    "            self.emb.weight.data.copy_(self.vocab.vectors) # copy the pretrained Glove vector as the initialization of the embeddings\n",
    "            \n",
    "        rnn_dropout = 0 if self.num_layers == 1 else self.dropout # PyTorch uses dropout only between 2 or more stacked RNN layers, thus if there's only one layer keep dropout to zero\n",
    "        if model == 'vanilla':\n",
    "            self.rnn = nn.RNN(input_size=self.emb_size, hidden_size=self.hidden_size, batch_first=True, num_layers=self.num_layers, dropout=rnn_dropout, bidirectional=self.bidirectional)\n",
    "        else:\n",
    "            self.rnn = nn.LSTM(input_size=self.emb_size, hidden_size=self.hidden_size, batch_first=True, num_layers=self.num_layers, dropout=rnn_dropout, bidirectional=self.bidirectional)\n",
    "        \n",
    "        h_size = self.hidden_size*2 if self.bidirectional else self.hidden_size # if we use bidirection RNN we get a twice the size of the hidden state size we defined\n",
    "        self.out = nn.Linear(h_size, 1)\n",
    "        \n",
    "        self.dropout_layer = nn.Dropout(self.dropout)\n",
    "        \n",
    "    def forward(self, x, lengths):\n",
    "        embed_x = self.dropout_layer(self.emb(x)) # pass the sequences through the embedding layer and through dropout\n",
    "        \n",
    "        # PyTorch allows for dynamic RNNs by packing the padded sequences\n",
    "        packed_emb = nn.utils.rnn.pack_padded_sequence(embed_x, lengths, batch_first=True) \n",
    "\n",
    "        # now run through RNN\n",
    "        output, hidden = self.rnn(packed_emb)\n",
    "\n",
    "        # undo the packing operation\n",
    "        output, _ = nn.utils.rnn.pad_packed_sequence(output, batch_first=True)\n",
    "                        \n",
    "        x = self.dropout_layer(output.mean(1)) # taking the average output representation of all times t in the sequence\n",
    "        x = self.out(x.squeeze(1))\n",
    "        return x.squeeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below are the functions responsible for training and testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, optimizer, criterion, epoch):\n",
    "    model.train()\n",
    "    loss_sum = 0\n",
    "    loss_count = 0\n",
    "    for batch_idx, data in enumerate(train_loader):\n",
    "        (x, x_lengths), y = data.text, data.label # extract the sequences and the true lengths of them alogn with the labels\n",
    "        optimizer.zero_grad()\n",
    "        output = model(x, x_lengths)\n",
    "        loss = criterion(output, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss_sum += loss.item()\n",
    "        loss_count += 1\n",
    "    return round(loss_sum/loss_count, 6)\n",
    "\n",
    "\n",
    "def test(model, test_loader, criterion, epoch):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    acc = 0\n",
    "    with torch.no_grad():\n",
    "        for data in test_loader:\n",
    "            (x, x_lengths), y = data.text, data.label\n",
    "            output = model(x, x_lengths)\n",
    "            test_loss += criterion(output, y).sum().item()\n",
    "            \n",
    "            rounded_preds = torch.round(torch.sigmoid(output))\n",
    "            correct = rounded_preds.eq(y.view_as(rounded_preds)).float()\n",
    "            acc += (correct.sum()/len(correct)).item()\n",
    "\n",
    "    test_loss /= len(test_loader)\n",
    "    acc /= len(test_loader)\n",
    "    return round(test_loss, 6), 100 * round(acc, 4)\n",
    "\n",
    "def experiment(model, epochs, training_iterator, testing_iterator, optimizer, criterion):\n",
    "    best_acc = -1\n",
    "    best_train_loss = -1\n",
    "    best_test_loss = -1\n",
    "    best_epoch = -1\n",
    "    for epoch in range(1, epochs+1):\n",
    "        train_loss = train(model, training_iterator, optimizer, criterion, epoch)\n",
    "        test_loss, acc = test(model, testing_iterator, criterion, epoch)\n",
    "        if acc >= best_acc: # used for find which epoch had the best accuracy\n",
    "            best_acc = acc\n",
    "            best_train_loss = train_loss\n",
    "            best_test_loss = test_loss\n",
    "            best_epoch = epoch\n",
    "            \n",
    "    return best_epoch, best_train_loss, best_test_loss, best_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4 - Running the experiments\n",
    "\n",
    "Below I'm going to run all the experiments for the different hyperparameters combinations and save the results into a CVS file. I decided that the three different hyperparameters that I will explore would be the dropout rate, the number of stacked RNN layers and if the RNNs be bidirectional or not.\n",
    "\n",
    "Note that due to computational resource, I couldn't run the experiments for 200 and 500 hidden states that include bidirectional model and 2 stacked RNN layers. \n",
    "\n",
    "All the experiments run for 5 epochs and with fixed 16 batch size (I couldn't test with different batch sizes due to computational resources). The learning rate was set to default according to the optimization algorithm (Adam). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_states = [20, 50, 100, 200, 500]\n",
    "dropouts = [0, 0.2, 0.5]\n",
    "num_layers = [1, 2]\n",
    "bidirectional = [False, True]\n",
    "rnn_types = ['vanilla', 'lstm']\n",
    "\n",
    "epochs = 5\n",
    "\n",
    "# We use the binary cross entropy error.\n",
    "# This one includes the sigmoid that the logits have to go through before the computation of the loss.\n",
    "# It's recommended this way instead of manually use the sigmoid in the model architecture \n",
    "# since PyTorch uses the log-sum-exp trick for better numerical stability.\n",
    "criterion = nn.BCEWithLogitsLoss().to(device)\n",
    "\n",
    "counter = 0\n",
    "\n",
    "filename = \"results.csv\"\n",
    "\n",
    "if os.path.exists(filename):\n",
    "    os.remove(filename)\n",
    "\n",
    "with open(filename, 'a+') as out:\n",
    "   out.write(\"rnn_type,\"+\"hidden_state,\"+\"dropout,\"+\"num_layers,\"+\"bidirectional,\"+\"best_epoch,\"+\"train_loss,\"+\"test_loss,\"+\"accuracy\"+'\\n')\n",
    "\n",
    "for rnn_type in rnn_types:\n",
    "    for hd in hidden_states:\n",
    "        for dp in dropouts:\n",
    "            for nl in num_layers:\n",
    "                for bd in bidirectional:\n",
    "                    counter += 1\n",
    "                    \n",
    "                    model = RNN(model=rnn_type, vocab=vocabulary, hidden_size=hd, dropout=dp, num_layers=nl, bidirectional=bd).to(device)\n",
    "                    optimizer = optim.Adam(model.parameters())\n",
    "                    \n",
    "                    best_epoch, best_train_loss, best_test_loss, best_acc = experiment(model, epochs, training_iterator, testing_iterator, optimizer, criterion)\n",
    "                    \n",
    "                    # used to empty gpu cache memory after each experiment\n",
    "                    del model\n",
    "                    torch.cuda.empty_cache()\n",
    "                    \n",
    "                    line = str(rnn_type)+\",\"+str(hd)+\",\"+str(dp)+\",\"+str(nl)+\",\"+str(bd)+\",\"+str(best_epoch)+\",\"+str(best_train_loss)+\",\"+str(best_test_loss)+\",\"+str(best_acc)\n",
    "                    print(counter, line)\n",
    "\n",
    "                    with open(filename, 'a+') as out:\n",
    "                       out.write(line + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5 - Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.read_csv(\"results.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, I report what is the best score between the best LSTM and vanilla RNN models. As you can see, LSTM has a much better accuracy than the vanilla RNN. An interesting result is that the LSTM model has achieved the best score after only one epoch and vanilla RNN had to run for 4 epochs and using 2 bidirectional RNN layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>rnn_type</th>\n",
       "      <th>hidden_state</th>\n",
       "      <th>dropout</th>\n",
       "      <th>num_layers</th>\n",
       "      <th>bidirectional</th>\n",
       "      <th>best_epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>test_loss</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rnn_type</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>lstm</th>\n",
       "      <th>112</th>\n",
       "      <td>lstm</td>\n",
       "      <td>500</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.330078</td>\n",
       "      <td>0.247589</td>\n",
       "      <td>90.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vanilla</th>\n",
       "      <th>11</th>\n",
       "      <td>vanilla</td>\n",
       "      <td>20</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.189767</td>\n",
       "      <td>0.312822</td>\n",
       "      <td>88.41</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             rnn_type  hidden_state  dropout  num_layers  bidirectional  \\\n",
       "rnn_type                                                                  \n",
       "lstm     112     lstm           500      0.2           1          False   \n",
       "vanilla  11   vanilla            20      0.5           2           True   \n",
       "\n",
       "              best_epoch  train_loss  test_loss  accuracy  \n",
       "rnn_type                                                   \n",
       "lstm     112         1.0    0.330078   0.247589     90.29  \n",
       "vanilla  11          4.0    0.189767   0.312822     88.41  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.groupby('rnn_type').apply(lambda t: t[t.accuracy==t.accuracy.max()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, I created some tables to show in each hidden state, which model best."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>rnn_type</th>\n",
       "      <th>hidden_state</th>\n",
       "      <th>dropout</th>\n",
       "      <th>num_layers</th>\n",
       "      <th>bidirectional</th>\n",
       "      <th>best_epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>test_loss</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rnn_type</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>lstm</th>\n",
       "      <th>71</th>\n",
       "      <td>lstm</td>\n",
       "      <td>20</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.195013</td>\n",
       "      <td>0.315640</td>\n",
       "      <td>88.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vanilla</th>\n",
       "      <th>11</th>\n",
       "      <td>vanilla</td>\n",
       "      <td>20</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.189767</td>\n",
       "      <td>0.312822</td>\n",
       "      <td>88.41</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            rnn_type  hidden_state  dropout  num_layers  bidirectional  \\\n",
       "rnn_type                                                                 \n",
       "lstm     71     lstm            20      0.5           2           True   \n",
       "vanilla  11  vanilla            20      0.5           2           True   \n",
       "\n",
       "             best_epoch  train_loss  test_loss  accuracy  \n",
       "rnn_type                                                  \n",
       "lstm     71         3.0    0.195013   0.315640     88.68  \n",
       "vanilla  11         4.0    0.189767   0.312822     88.41  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[results['hidden_state']==20].groupby('rnn_type').apply(lambda t: t[t.accuracy==t.accuracy.max()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>rnn_type</th>\n",
       "      <th>hidden_state</th>\n",
       "      <th>dropout</th>\n",
       "      <th>num_layers</th>\n",
       "      <th>bidirectional</th>\n",
       "      <th>best_epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>test_loss</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rnn_type</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>lstm</th>\n",
       "      <th>79</th>\n",
       "      <td>lstm</td>\n",
       "      <td>50</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.401064</td>\n",
       "      <td>0.275062</td>\n",
       "      <td>89.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vanilla</th>\n",
       "      <th>15</th>\n",
       "      <td>vanilla</td>\n",
       "      <td>50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.404624</td>\n",
       "      <td>0.302325</td>\n",
       "      <td>87.91</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            rnn_type  hidden_state  dropout  num_layers  bidirectional  \\\n",
       "rnn_type                                                                 \n",
       "lstm     79     lstm            50      0.2           2           True   \n",
       "vanilla  15  vanilla            50      0.0           2           True   \n",
       "\n",
       "             best_epoch  train_loss  test_loss  accuracy  \n",
       "rnn_type                                                  \n",
       "lstm     79         1.0    0.401064   0.275062     89.03  \n",
       "vanilla  15         1.0    0.404624   0.302325     87.91  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[results['hidden_state']==50].groupby('rnn_type').apply(lambda t: t[t.accuracy==t.accuracy.max()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>rnn_type</th>\n",
       "      <th>hidden_state</th>\n",
       "      <th>dropout</th>\n",
       "      <th>num_layers</th>\n",
       "      <th>bidirectional</th>\n",
       "      <th>best_epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>test_loss</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rnn_type</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>lstm</th>\n",
       "      <th>87</th>\n",
       "      <td>lstm</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.360739</td>\n",
       "      <td>0.262898</td>\n",
       "      <td>89.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vanilla</th>\n",
       "      <th>35</th>\n",
       "      <td>vanilla</td>\n",
       "      <td>100</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.173499</td>\n",
       "      <td>0.342928</td>\n",
       "      <td>87.45</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            rnn_type  hidden_state  dropout  num_layers  bidirectional  \\\n",
       "rnn_type                                                                 \n",
       "lstm     87     lstm           100      0.0           2           True   \n",
       "vanilla  35  vanilla           100      0.5           2           True   \n",
       "\n",
       "             best_epoch  train_loss  test_loss  accuracy  \n",
       "rnn_type                                                  \n",
       "lstm     87         1.0    0.360739   0.262898     89.72  \n",
       "vanilla  35         4.0    0.173499   0.342928     87.45  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[results['hidden_state']==100].groupby('rnn_type').apply(lambda t: t[t.accuracy==t.accuracy.max()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>rnn_type</th>\n",
       "      <th>hidden_state</th>\n",
       "      <th>dropout</th>\n",
       "      <th>num_layers</th>\n",
       "      <th>bidirectional</th>\n",
       "      <th>best_epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>test_loss</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rnn_type</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>lstm</th>\n",
       "      <th>104</th>\n",
       "      <td>lstm</td>\n",
       "      <td>200</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.355361</td>\n",
       "      <td>0.259895</td>\n",
       "      <td>89.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vanilla</th>\n",
       "      <th>40</th>\n",
       "      <td>vanilla</td>\n",
       "      <td>200</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.166254</td>\n",
       "      <td>0.322346</td>\n",
       "      <td>87.22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             rnn_type  hidden_state  dropout  num_layers  bidirectional  \\\n",
       "rnn_type                                                                  \n",
       "lstm     104     lstm           200      0.5           1          False   \n",
       "vanilla  40   vanilla           200      0.2           1          False   \n",
       "\n",
       "              best_epoch  train_loss  test_loss  accuracy  \n",
       "rnn_type                                                   \n",
       "lstm     104         1.0    0.355361   0.259895     89.69  \n",
       "vanilla  40          4.0    0.166254   0.322346     87.22  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[results['hidden_state']==200].groupby('rnn_type').apply(lambda t: t[t.accuracy==t.accuracy.max()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>rnn_type</th>\n",
       "      <th>hidden_state</th>\n",
       "      <th>dropout</th>\n",
       "      <th>num_layers</th>\n",
       "      <th>bidirectional</th>\n",
       "      <th>best_epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>test_loss</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rnn_type</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>lstm</th>\n",
       "      <th>112</th>\n",
       "      <td>lstm</td>\n",
       "      <td>500</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.330078</td>\n",
       "      <td>0.247589</td>\n",
       "      <td>90.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vanilla</th>\n",
       "      <th>52</th>\n",
       "      <td>vanilla</td>\n",
       "      <td>500</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.181922</td>\n",
       "      <td>0.330636</td>\n",
       "      <td>86.82</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             rnn_type  hidden_state  dropout  num_layers  bidirectional  \\\n",
       "rnn_type                                                                  \n",
       "lstm     112     lstm           500      0.2           1          False   \n",
       "vanilla  52   vanilla           500      0.2           1          False   \n",
       "\n",
       "              best_epoch  train_loss  test_loss  accuracy  \n",
       "rnn_type                                                   \n",
       "lstm     112         1.0    0.330078   0.247589     90.29  \n",
       "vanilla  52          3.0    0.181922   0.330636     86.82  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[results['hidden_state']==500].groupby('rnn_type').apply(lambda t: t[t.accuracy==t.accuracy.max()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's easy to see that the best vanilla RNN models were 2-layer bidirectional models but with a hidden state of 200 and 500 there are enough parameters to fit a good model and the versions with 2-layers and bidirectional options for 200 and 500 probably overfitted the training set.\n",
    "\n",
    "Also, as we increase the hidden state of the LSTM we notice that we gradually get better results."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
